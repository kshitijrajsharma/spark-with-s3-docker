x-spark-volumes: &spark-volumes
  - ${SCRIPTS_PATH:-./scripts}:/opt/spark/work-dir/scripts
  - ${DATA_PATH:-./data}:/opt/spark/work-dir/data
  - ${LOGS_PATH:-./spark-logs}:/opt/spark/spark-events
  - ${WAREHOUSE_PATH:-./warehouse}:/opt/spark/work-dir/warehouse
  - ~/.aws:/root/.aws

services:
  spark-master:
    image: ${SPARK_IMAGE:-ghcr.io/kshitijrajsharma/spark-aws:latest}
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MASTER_PORT=${MASTER_PORT:-7077}
      - SPARK_MASTER_WEBUI_PORT=${MASTER_UI_PORT:-8080}
      - SPARK_DRIVER_MEMORY=${SPARK_DRIVER_MEMORY:-2g}
      - SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY:-4g}
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=/opt/spark/spark-events
      - PATH=/opt/spark/bin:/opt/spark/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
    volumes: *spark-volumes
    ports:
      - '${MASTER_UI_PORT:-8080}:8080'
      - '${MASTER_PORT:-7077}:7077'

  spark-worker:
    image: ${SPARK_IMAGE:-ghcr.io/kshitijrajsharma/spark-aws:latest}
    build:
      context: .
      dockerfile: Dockerfile.spark
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:${MASTER_PORT:-7077}
    environment:
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES:-2}
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY:-2g}
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=/opt/spark/spark-events
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
    depends_on:
      - spark-master
    volumes: *spark-volumes

  spark-history:
    image: ${SPARK_IMAGE:-ghcr.io/kshitijrajsharma/spark-aws:latest}
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-history
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark/spark-events
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
    depends_on:
      - spark-master
    volumes: *spark-volumes
    ports:
      - '${HISTORY_UI_PORT:-18080}:18080'

  jupyter:
    image: ${JUPYTER_IMAGE:-ghcr.io/kshitijrajsharma/spark-jupyter:latest}
    build:
      context: .
      dockerfile: Dockerfile.jupyter
    container_name: spark-jupyter
    environment:
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-spark}
      - SPARK_MASTER_URL=spark://spark-master:${MASTER_PORT:-7077}
      - SPARK_DRIVER_MEMORY=${SPARK_DRIVER_MEMORY:-2g}
      - SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY:-4g}
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=/opt/spark/spark-events
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
    depends_on:
      - spark-master
    volumes:
      - *spark-volumes
      - ${NOTEBOOKS_PATH:-./notebooks}:/home/jovyan/notebooks
    ports:
      - '${JUPYTER_PORT:-8889}:8888'

volumes:
  spark-logs: